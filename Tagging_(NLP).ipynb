{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tagging (NLP).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnuragBhattacharjee17/Natural-Language-Processing/blob/master/Tagging_(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOqPKox9dK3a",
        "colab_type": "text"
      },
      "source": [
        "NLTK provides different taggers that we can train and use in order to tag our unseen text data more efficiently. The taggers are:\n",
        "\n",
        "Default tagger\n",
        "\n",
        "Lookup taggers:\n",
        "\n",
        "Unigram tagger - context independent tagging\n",
        "\n",
        "Ngram tagger - context dependent tagging\n",
        "\n",
        "Regular Expression Tagger\n",
        "\n",
        "We can also use a combination of these taggers to tag a sentence with the concept of backoff. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-TG6OW9cRqV",
        "colab_type": "code",
        "outputId": "59ad1702-b06d-4702-be17-5f855010156f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#DEFAULT TAGGER\n",
        "#The default tagger assigns the same tag to each token, this is considered the most naive tagger.\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "sent = \"The gentlemen wants some water to water the plants\"\n",
        "word_token= nltk.word_tokenize(sent)\n",
        "print(word_token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['The', 'gentlemen', 'wants', 'some', 'water', 'to', 'water', 'the', 'plants']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PazgtCTb-FuI",
        "colab_type": "code",
        "outputId": "ed9070db-1bee-4928-f256-1d3aaee61685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Getting most common tag\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "tag = pos_tag(word_token)\n",
        "Feq_tag = max(nltk.FreqDist(tag))\n",
        "print(Feq_tag[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-eTrwJu--iC",
        "colab_type": "code",
        "outputId": "eb4e8038-35a6-401b-bee3-2a9b30584450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Using the most_common_tag as the input for DefaultTagger\n",
        "from nltk import DefaultTagger\n",
        "default_tagger = DefaultTagger(Feq_tag[1])\n",
        "final = default_tagger.tag(word_token)\n",
        "print(final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'NN'), ('gentlemen', 'NN'), ('wants', 'NN'), ('some', 'NN'), ('water', 'NN'), ('to', 'NN'), ('water', 'NN'), ('the', 'NN'), ('plants', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEFwbiyQC0dR",
        "colab_type": "text"
      },
      "source": [
        "**Lookup Tagger**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH5nF2AiBxoi",
        "colab_type": "code",
        "outputId": "e2767b03-9991-4d1d-88f2-c036362bda6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Lookup Tagger\n",
        "#A NgramTagger tags a word based on the previous n words occurring in the text.\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "sent1 = \"the quick brown fox jumps over the lazy dog\"\n",
        "training_tags= pos_tag(word_tokenize(sent1))\n",
        "print(training_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRjzEcXBC9G_",
        "colab_type": "code",
        "outputId": "1f6c0102-6611-4b7a-afb4-2da5a314c024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Now let us use these tags to train the NgramTagger\n",
        "ngram_tagger = nltk.NgramTagger(n=2,train=[training_tags])\n",
        "print(ngram_tagger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<NgramTagger: size=9>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgC5yuKWDd7R",
        "colab_type": "code",
        "outputId": "7bd34b79-1c77-49ab-b355-6bb2ae524dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sent2 = \"the lazy dog was jumped over by the quick brown fox\"\n",
        "ngram_tag = ngram_tagger.tag(word_tokenize(sent2))\n",
        "print(ngram_tag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('was', None), ('jumped', None), ('over', None), ('by', None), ('the', None), ('quick', None), ('brown', None), ('fox', None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxuzmYtiEUIP",
        "colab_type": "text"
      },
      "source": [
        " The NgramTagger then does a lookup for matching bigrams in the training data and uses that to tag the new data.\n",
        "\n",
        "Since the pairs (the, lazy) and (lazy, dog) appear in the training data, the tagger is able to tag the words \"the\", \"lazy\" and \"dog\". \n",
        "\n",
        "When it encounters the pair (dog, was) , this sequence was never present in the training data; so it assigns None to the word \"was\" and all other words succeeding it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyOJO3IMGGhG",
        "colab_type": "text"
      },
      "source": [
        "**Unigram Tagger**\n",
        "UnigramTagger is a special case of NgramTagger where n=1. When n=1, then the NgramTagger has no context, i.e. each word is looked up independently in the training set. Therefore the UnigramTagger is also referred to as the context independent tagger.\n",
        "\n",
        "The UnigramTagger performs a looks up the query word in the training data and assigns the most common tag associated with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtIuJAgVEVXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "barack = \"\"\"Barack Hussein Obama II born August 4, 1961) is an American politician\n",
        "who served as the 44th President of \n",
        "the United States from January 20, 2009, to January 20, 2017.\n",
        "A member of the Democratic Party, he was the \n",
        "first African American to assume the presidency and previously\n",
        "served as a United States Senator from Illinois (2005â€“2008).\"\"\"\n",
        "\n",
        "bush = \"\"\"George Walker Bush (born July 6, 1946) is an American politician who served as the 43rd President\n",
        " of the United States from 2001 to 2009.\n",
        "He had previously served as the 46th Governor of Texas from 1995 to 2000.\n",
        "Bush was born New Haven, Connecticut, and grew up in Texas. \n",
        "After graduating from Yale University in 1968 and Harvard Business School in 1975, he worked in the oil industry.\n",
        "Bush married Laura Welch in 1977 and unsuccessfully ran for the U.S. House of Representatives shortly thereafter. \n",
        "He later co-owned the Texas Rangers baseball team before defeating Ann Richards in the 1994 Texas gubernatorial election. \n",
        "Bush was elected President of the United States in 2000 when he defeated Democratic incumbent \n",
        "Vice President Al Gore after a close and controversial win that involved a stopped recount in Florida. \n",
        "He became the fourth person to be elected president while receiving fewer popular votes than his opponent.\n",
        "Bush is a member of a prominent political family and is the eldest son of Barbara and George H. W. Bush, \n",
        "the 41st President of the United States. \n",
        "He is only the second president to assume the nation's highest office after his father, following the footsteps\n",
        " of John Adams and his son, John Quincy Adams.\n",
        "His brother, Jeb Bush, a former Governor of Florida, was a candidate for the Republican presidential nomination\n",
        " in the 2016 presidential election. \n",
        "His paternal grandfather, Prescott Bush, was a U.S. Senator from Connecticut.\"\"\"\n",
        "\n",
        "pos_tag_barack = pos_tag(word_tokenize(barack))\n",
        "pos_tag_bush = pos_tag(word_tokenize(bush))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtoHl3_1GqTJ",
        "colab_type": "code",
        "outputId": "2c40dfde-db3f-4ef9-e342-907c1f0ad88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "trump = \"\"\"Donald John Trump (born June 14, 1946) is the 45th and current President of the United States.\n",
        "Before entering politics, he was a businessman and television personality. \n",
        "Trump was born and raised in the New York City borough of Queens, and received an economics degree from the\n",
        " Wharton School of the University of Pennsylvania. \n",
        "He took charge of his family's real estate business in 1971, renamed it The Trump Organization, and expanded \n",
        "it from Queens and Brooklyn into Manhattan. \n",
        "The company built or renovated skyscrapers, hotels, casinos, and golf courses. \n",
        "Trump later started various side ventures, including licensing his name for real estate and consumer products.\n",
        "He managed the company until his 2017 inauguration. \n",
        "He co-authored several books, including The Art of the Deal. He owned the Miss Universe and Miss USA beauty \n",
        "pageants from 1996 to 2015, and he produced and hosted the reality television show The Apprentice from 2003 to 2015.\n",
        "Forbes estimates his net worth to be $3.1 billion.\"\"\"\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train=[pos_tag_barack,pos_tag_bush])\n",
        "unigram_tag = unigram_tagger.tag(word_tokenize(trump))\n",
        "print(unigram_tag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Donald', None), ('John', 'NNP'), ('Trump', None), ('(', '('), ('born', 'VBN'), ('June', None), ('14', None), (',', ','), ('1946', 'CD'), (')', ')'), ('is', 'VBZ'), ('the', 'DT'), ('45th', None), ('and', 'CC'), ('current', None), ('President', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('.', '.'), ('Before', None), ('entering', None), ('politics', None), (',', ','), ('he', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('businessman', None), ('and', 'CC'), ('television', None), ('personality', None), ('.', '.'), ('Trump', None), ('was', 'VBD'), ('born', 'VBN'), ('and', 'CC'), ('raised', None), ('in', 'IN'), ('the', 'DT'), ('New', 'NNP'), ('York', None), ('City', None), ('borough', None), ('of', 'IN'), ('Queens', None), (',', ','), ('and', 'CC'), ('received', None), ('an', 'DT'), ('economics', None), ('degree', None), ('from', 'IN'), ('the', 'DT'), ('Wharton', None), ('School', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('University', 'NNP'), ('of', 'IN'), ('Pennsylvania', None), ('.', '.'), ('He', 'PRP'), ('took', None), ('charge', None), ('of', 'IN'), ('his', 'PRP$'), ('family', 'NN'), (\"'s\", 'POS'), ('real', None), ('estate', None), ('business', None), ('in', 'IN'), ('1971', None), (',', ','), ('renamed', None), ('it', None), ('The', None), ('Trump', None), ('Organization', None), (',', ','), ('and', 'CC'), ('expanded', None), ('it', None), ('from', 'IN'), ('Queens', None), ('and', 'CC'), ('Brooklyn', None), ('into', None), ('Manhattan', None), ('.', '.'), ('The', None), ('company', None), ('built', None), ('or', None), ('renovated', None), ('skyscrapers', None), (',', ','), ('hotels', None), (',', ','), ('casinos', None), (',', ','), ('and', 'CC'), ('golf', None), ('courses', None), ('.', '.'), ('Trump', None), ('later', 'RB'), ('started', None), ('various', None), ('side', None), ('ventures', None), (',', ','), ('including', None), ('licensing', None), ('his', 'PRP$'), ('name', None), ('for', 'IN'), ('real', None), ('estate', None), ('and', 'CC'), ('consumer', None), ('products', None), ('.', '.'), ('He', 'PRP'), ('managed', None), ('the', 'DT'), ('company', None), ('until', None), ('his', 'PRP$'), ('2017', 'CD'), ('inauguration', None), ('.', '.'), ('He', 'PRP'), ('co-authored', None), ('several', None), ('books', None), (',', ','), ('including', None), ('The', None), ('Art', None), ('of', 'IN'), ('the', 'DT'), ('Deal', None), ('.', '.'), ('He', 'PRP'), ('owned', None), ('the', 'DT'), ('Miss', None), ('Universe', None), ('and', 'CC'), ('Miss', None), ('USA', None), ('beauty', None), ('pageants', None), ('from', 'IN'), ('1996', None), ('to', 'TO'), ('2015', None), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('produced', None), ('and', 'CC'), ('hosted', None), ('the', 'DT'), ('reality', None), ('television', None), ('show', None), ('The', None), ('Apprentice', None), ('from', 'IN'), ('2003', None), ('to', 'TO'), ('2015', None), ('.', '.'), ('Forbes', None), ('estimates', None), ('his', 'PRP$'), ('net', None), ('worth', None), ('to', 'TO'), ('be', 'VB'), ('$', None), ('3.1', None), ('billion', None), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}