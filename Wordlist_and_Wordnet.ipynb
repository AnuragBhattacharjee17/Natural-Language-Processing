{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wordlist and Wordnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRLA033u/67uHjaBOaG5jq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnuragBhattacharjee17/Natural-Language-Processing/blob/master/Wordlist_and_Wordnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pruo-2abYnrN",
        "colab_type": "text"
      },
      "source": [
        "**Detect unusual words in text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6GJU42dbRu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "89d8c3d1-bd83-40ca-e833-ae70be379b6b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download(\"names\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2_QoncPYiTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent1 = \"\"\"Just forced myself to eat a slice. I'm really not hungry tho. \n",
        "           Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\"\"\"\n",
        "sent2 = \"I call you later, don't have nw. If urgnt, sms me.\"\n",
        "sent3 = \"Watching a telugu movie..wat abt u?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mdk_OJ3Yli2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_unusual_word(text):\n",
        "  text_set = set(w.lower() for w in text if w.isalpha())\n",
        "  dictionary_set = set (w.lower() for w in nltk.corpus.words.words())\n",
        "  unusual_set = text_set - dictionary_set\n",
        "  return sorted(unusual_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pw0GXV3Z3UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d5deda-9718-4dac-ba2a-5123cd1e2682"
      },
      "source": [
        "print(find_unusual_word(nltk.word_tokenize(sent2)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nw', 'sms', 'urgnt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWsiGeS4bEtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc62d154-e805-4420-f18e-00e31fc6325e"
      },
      "source": [
        "print(find_unusual_word(nltk.word_tokenize(sent1)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['knows', 'lol']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYXsNrNwbN01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43b8b467-687e-4455-d152-3bfb3b43c2d4"
      },
      "source": [
        "print(find_unusual_word(nltk.word_tokenize(sent3)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIzJgX4nn7Pb",
        "colab_type": "text"
      },
      "source": [
        "**Detect Spelling Mistakes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJRR2dx2n--l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4825f04c-12d8-4968-eec9-318e2a0487c7"
      },
      "source": [
        "#If a word could not found in the word list, it is probable that it is a spelling mistake.\n",
        "\n",
        "#The below code, compares the unusual words with known words and suggests possible words based on edit distance.\n",
        "# Edit distance is the measure of how similar or dissimilar two words are. \n",
        "\n",
        "unusual_word_set=[\"nw\",\"sms\",\"urgnt\",\"lol\",\"abt\"]\n",
        "from nltk.metrics import edit_distance\n",
        "possible_suggestions = {}\n",
        "dictionary_set = set (w.lower() for w in nltk.corpus.words.words())\n",
        "for unusual_word in unusual_word_set:\n",
        "  for right_word in dictionary_set:\n",
        "    dist=edit_distance(unusual_word,right_word)\n",
        "    if dist < len(unusual_word)/2:\n",
        "      if unusual_word not in possible_suggestions.keys():\n",
        "        possible_suggestions[unusual_word]= right_word\n",
        "      else:\n",
        "        possible_suggestions[unusual_word]= right_word\n",
        "print(possible_suggestions[\"lol\"])\n",
        "        \n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lou\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAwNX_EBxJhk",
        "colab_type": "text"
      },
      "source": [
        "**Detect Names of People in Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYa2k4YxRJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33549683-7c9c-4cf7-d6ab-64376ae3bc2a"
      },
      "source": [
        "def detect_names(text):\n",
        "  names=[]\n",
        "  word_set = set(w for w in text if w.isalpha())\n",
        "  male_names = nltk.corpus.names.words(\"male.txt\")\n",
        "  for word in word_set:\n",
        "    for name in male_names:\n",
        "      if(word==name):\n",
        "        names.append(name)\n",
        "  return names\n",
        "sent = \"Anurag is a good boy\"\n",
        "print(detect_names(nltk.word_tokenize(sent)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Anurag']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wucVQnpGzqox",
        "colab_type": "text"
      },
      "source": [
        "**WORDNET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7NJ3D-tzuox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c354dcec-3abf-4a2d-ede5-f3bdecdc8bd6"
      },
      "source": [
        "#WordNet is a lexical database for English created at Princeton University. It contains over 150,000 words and 110,000 synonyms.\n",
        "\n",
        "# below code demonstrates the various methods of wordnet package of nltk.\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "#get all possible meanings of dog\n",
        "print(wn.synsets(\"dog\"))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3wBCg6528-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80418c21-6985-4ead-f1f1-8f02d9d0d6c2"
      },
      "source": [
        "#Get all hypernyms of \"dog\"\n",
        "print(wn.synset('dog.n.01').hypernyms())\n",
        "# A hypernym is the generic term where as a hyponym is a specific term\n",
        "# For the word dog, the hypernyms are 'canine' and 'domestic_animal'"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRKo0PRd3Lx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6e79a170-afd6-4bb4-8de4-6325fbc0b2ec"
      },
      "source": [
        "#Get all hyponyms of \"dog\"\n",
        "print(wn.synset('dog.n.01').hyponyms())\n",
        "# some of hyponyms are  \"pug\", \"puppy\", \"lap_dog\", etc."
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik0yaIoA3Vci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67ff681c-6125-4140-c00b-dd37a2c79a7c"
      },
      "source": [
        "\n",
        "#Get the path similarity between to words - the method returns the shortest path in the taxonomy\n",
        "dog = wn.synset('dog.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "print(cat.path_similarity(dog)) #Returns a value between 0 and 1. The higher the number, higher the similarity in path"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}